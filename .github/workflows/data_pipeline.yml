name: Data Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - incident/*

jobs:
  # 1. Compliance Check (Runs on every PR)
  compliance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Needed for git diff
      
      - name: Check Restricted Files
        run: |
          chmod +x script/check_compliance.sh
          ./script/check_compliance.sh

  # 2. Verify & Mine (Runs on PR to Incident branch)
  verify_mine:
    needs: compliance
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: foundry-rs/foundry-toolchain@v1
      
      - name: Run Tests (Verified Mode)
        env:
          CI: true # This triggers data/verified/ path
          # Secrets needed for forking
          MAINNET_RPC_URL: ${{ secrets.MAINNET_RPC_URL }}
        run: forge test -vvv
      
      - name: Upload Verified Artifacts
        uses: actions/upload-artifact@v3
        with:
          name: verified-data
          path: data/verified/*.json
          retention-days: 1

  # 3. Aggregate (Runs only on Push to Main)
  aggregate:
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      
      # In a real scenario, we would download artifacts from the PR that was just merged.
      # However, since artifacts don't persist across workflow runs easily without external storage,
      # we re-run the tests on main to generate the official "Golden Data".
      - uses: foundry-rs/foundry-toolchain@v1
      
      - name: Generate Official Data
        env:
          CI: true
          MAINNET_RPC_URL: ${{ secrets.MAINNET_RPC_URL }}
        run: forge test -vvv
        
      - name: Aggregate to CSV
        run: python3 script/json_to_csv.py
        
      - name: Commit Dataset
        uses: stefanzweifel/git-auto-commit-action@v4
        with:
          commit_message: "chore(data): update official dataset [skip ci]"
          file_pattern: data/dataset.csv
          commit_user_name: AuditBot
          commit_user_email: bot@audit.org
